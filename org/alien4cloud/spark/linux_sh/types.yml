tosca_definitions_version: alien_dsl_2_0_0

metadata:
  template_name: org.alien4cloud.spark.linux_sh
  template_version: 2.2.0-SNAPSHOT
  template_author: alien4cloud

description: |
  Spark cluster linux concrete types.

imports:
  - tosca-normative-types:1.0.0-ALIEN20
  - org.alien4cloud.java.pub:2.2.0-SNAPSHOT
  - org.alien4cloud.spark.pub:2.2.0-SNAPSHOT

node_types:

  org.alien4cloud.spark.linux_sh.nodes.SparkMaster:
    derived_from: org.alien4cloud.spark.pub.nodes.SparkMaster
    interfaces:
      Standard:
        create:
          inputs:
            SPARK_DOWNLOAD_URL: { get_property: [SELF, download_url] }
            SPARK_INSTALL_DIR: { get_property: [SELF, install_dir] }
          implementation: scripts/install_spark.sh
        configure:
          inputs:
            SPARK_INSTALL_DIR: { get_property: [SELF, install_dir] }
            SPARK_MASTER_REST_PORT: {get_property: [ SELF, spark_rest, port ]}
          implementation: scripts/configure_master.sh
        start:
          inputs:
            SPARK_INSTALL_DIR: { get_property: [SELF, install_dir] }
            SPARK_MASTER_ADDRESS: { get_attribute: [HOST, ip_address] }
            SPARK_UI_PORT: {get_property: [ SELF, spark_ui, port ]}
            SPARK_MASTER_PORT: {get_property: [ SELF, spark_master, port ]}
          implementation: scripts/start_master.sh
        stop:
          implementation: scripts/stop_master.sh
        delete:
          inputs:
            SPARK_INSTALL_DIR: { get_property: [SELF, install_dir] }
          implementation: scripts/uninstall_spark.sh

  org.alien4cloud.spark.linux_sh.nodes.SparkWorker:
    derived_from: org.alien4cloud.spark.pub.nodes.SparkWorker
    interfaces:
      Standard:
        create:
          inputs:
            SPARK_DOWNLOAD_URL: { get_property: [SELF, download_url] }
            SPARK_INSTALL_DIR: { get_property: [SELF, install_dir] }
          implementation: scripts/install_spark.sh
        start:
          # For Alien4Cloud UI to not show the component deployment status as
          # being in progress
          implementation: scripts/start_noop.sh
        stop:
          implementation: scripts/stop_worker.sh
        delete:
          inputs:
            SPARK_INSTALL_DIR: { get_property: [SELF, install_dir] }
          implementation: scripts/uninstall_spark.sh

relationship_types:

  org.alien4cloud.spark.linux_sh.relationships.JoinSparkCluster:
    derived_from: org.alien4cloud.spark.pub.relationships.JoinSparkCluster
    valid_target_types: [org.alien4cloud.spark.linux_sh.nodes.SparkMaster]
    interfaces:
      Configure:
        add_target:
          inputs:
            SPARK_INSTALL_DIR: { get_property: [SOURCE, install_dir] }
            SPARK_MASTER_ADDRESS: { get_attribute: [TARGET, ip_address] }
            SPARK_WORKER_ADDRESS: { get_attribute: [SOURCE, ip_address] }
            SPARK_MASTER_PORT: { get_attribute: [TARGET, spark_master, port] }
          implementation: scripts/join_spark_cluster.sh
